{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import vectorbtpro as vbt\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "vbt.settings.set_theme(\"dark\")\n",
    "vbt.settings.plotting[\"layout\"][\"width\"] = 800\n",
    "vbt.settings.plotting['layout']['height'] = 200\n",
    "vbt.settings.plotting.use_resampler = True\n",
    "# show all columns\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data for BTC and ETH and put them in a single data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "btc_data_path = '/Users/ericervin/Documents/Coding/data-repository/data/fixed_BTCUSDT.csv'\n",
    "eth_data_path = '/Users/ericervin/Documents/Coding/data-repository/data/fixed_ETHUSDT.csv'\n",
    "eth_min_data = vbt.BinanceData.from_csv(eth_data_path)\n",
    "btc_min_data = vbt.BinanceData.from_csv(btc_data_path)\n",
    "print(eth_min_data.shape)\n",
    "print(btc_min_data.shape)\n",
    "# Create a combined data object with both ETH and BTC\n",
    "min_data = vbt.BinanceData.merge(\n",
    "    eth_min_data.rename({'fixed_ETHUSDT': 'ETH'}), \n",
    "    btc_min_data.rename({'fixed_BTCUSDT': 'BTC'}), \n",
    "    missing_index='drop')\n",
    "print(min_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit(nogil=True)\n",
    "def psar_nb_with_next(high, low, close, af0=0.02, af_increment=0.02, max_af=0.2):\n",
    "    length = len(high)\n",
    "    long = np.full(length, np.nan)  # Equivalent to PSARl\n",
    "    short = np.full(length, np.nan)  # Equivalent to PSARs\n",
    "    af = np.full(length, np.nan)  # Equivalent to PSARaf\n",
    "    reversal = np.zeros(length, dtype=np.int_)  # Equivalent to PSARr\n",
    "    next_long = np.full(length, np.nan)  # Next bar's PSAR for long\n",
    "    next_short = np.full(length, np.nan)  # Next bar's PSAR for short\n",
    "\n",
    "    falling = False\n",
    "    acceleration_factor = af0\n",
    "    extreme_point = high[0] if falling else low[0]\n",
    "    sar = low[0] if falling else high[0]\n",
    "\n",
    "    for i in range(1, length):\n",
    "        # Calculate current PSAR\n",
    "        if falling:\n",
    "            sar = max(sar + acceleration_factor * (extreme_point - sar), high[i-1], high[i-2] if i > 1 else high[i-1])\n",
    "            if high[i] > sar:\n",
    "                falling = False\n",
    "                reversal[i] = 1\n",
    "                sar = extreme_point\n",
    "                extreme_point = high[i]\n",
    "                acceleration_factor = af0\n",
    "        else:\n",
    "            sar = min(sar + acceleration_factor * (extreme_point - sar), low[i-1], low[i-2] if i > 1 else low[i-1])\n",
    "            if low[i] < sar:\n",
    "                falling = True\n",
    "                reversal[i] = 1\n",
    "                sar = extreme_point\n",
    "                extreme_point = low[i]\n",
    "                acceleration_factor = af0\n",
    "\n",
    "        if falling:\n",
    "            if low[i] < extreme_point:\n",
    "                extreme_point = low[i]\n",
    "                acceleration_factor = min(acceleration_factor + af_increment, max_af)\n",
    "            short[i] = sar\n",
    "        else:\n",
    "            if high[i] > extreme_point:\n",
    "                extreme_point = high[i]\n",
    "                acceleration_factor = min(acceleration_factor + af_increment, max_af)\n",
    "            long[i] = sar\n",
    "\n",
    "        af[i] = acceleration_factor\n",
    "\n",
    "        # Calculate next bar's PSAR\n",
    "        if i < length - 1:\n",
    "            next_sar = sar + acceleration_factor * (extreme_point - sar)\n",
    "            if falling:\n",
    "                next_short[i] = max(next_sar, high[i], high[i-1] if i > 0 else high[i])\n",
    "            else:\n",
    "                next_long[i] = min(next_sar, low[i], low[i-1] if i > 0 else low[i])\n",
    "\n",
    "    return long, short, af, reversal, next_long, next_short\n",
    "\n",
    "# Usage example:\n",
    "eth_min = eth_min_data.get()\n",
    "high_prices = eth_min['High'].values\n",
    "low_prices = eth_min['Low'].values\n",
    "close_prices = eth_min['Close'].values\n",
    "\n",
    "psarl, psars, psaraf, psarr, next_psarl, next_psars = psar_nb_with_next(high_prices, low_prices, close_prices)\n",
    "\n",
    "# Add the PSAR values to the DataFrame\n",
    "eth_min['psarl'] = psarl\n",
    "eth_min['psars'] = psars\n",
    "eth_min['next_psarl'] = next_psarl\n",
    "eth_min['next_psars'] = next_psars\n",
    "\n",
    "date_range = slice('2021-01-03', '2021-01-03 00:30:00')\n",
    "eth_min.loc[date_range]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorbt indicator factory\n",
    "PSAR = vbt.IF(\n",
    "    class_name = 'PSAR',\n",
    "    short_name = 'psar',\n",
    "    input_names = ['high', 'low', 'close'],\n",
    "    param_names = ['af_0', 'af', 'max_af'],\n",
    "    output_names = ['psarl', 'psars', 'psaraf', 'psarr', 'next_psarl', 'next_psars'],\n",
    ").with_apply_func(\n",
    "    psar_nb_with_next,\n",
    "    takes_1d=True,\n",
    "    af_0=0.02,\n",
    "    af=0.02,\n",
    "    max_af=0.2,\n",
    "    param_product=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbt.phelp(PSAR.run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These params could be single values or lists of values\n",
    "af_0 = 0.01\n",
    "af = 0.001\n",
    "max_af = 0.15\n",
    "\n",
    "psar = PSAR.run(\n",
    "    eth_min_data.high, \n",
    "    eth_min_data.low, \n",
    "    eth_min_data.close, \n",
    "    af_0=af_0, \n",
    "    af=af, \n",
    "    max_af=max_af\n",
    "    )\n",
    "psar_df = pd.concat([eth_min_data.get(), psar.psarl, psar.psars, psar.psarr, psar.next_psarl, psar.next_psars], axis=1)\n",
    "\n",
    "psar_df.columns = ['Open', 'High', 'Low', 'Close', 'psarl', 'psars', 'psarr', 'next_psarl', 'next_psars']\n",
    "\n",
    "# Calculate how many times the psar reversed\n",
    "psar.psarr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class helps us plot the PSAR indicator\n",
    "\n",
    "class PSAR(PSAR):\n",
    "    def plot(self, \n",
    "             column=None, \n",
    "             close_kwargs=None,\n",
    "             psarl_kwargs=None,\n",
    "             psars_kwargs=None,\n",
    "             next_psarl_kwargs=None,\n",
    "             next_psars_kwargs=None,\n",
    "             fig=None, \n",
    "             **layout_kwargs):\n",
    "        close_kwargs = close_kwargs if close_kwargs else {}\n",
    "        psarl_kwargs = psarl_kwargs if psarl_kwargs else {}\n",
    "        psars_kwargs = psars_kwargs if psars_kwargs else {}\n",
    "        next_psarl_kwargs = next_psarl_kwargs if next_psarl_kwargs else {}\n",
    "        next_psars_kwargs = next_psars_kwargs if next_psars_kwargs else {}\n",
    "        \n",
    "        close = self.select_col_from_obj(self.close, column).rename('Close')\n",
    "        psarl = self.select_col_from_obj(self.psarl, column).rename('Long')\n",
    "        psars = self.select_col_from_obj(self.psars, column).rename('Short')\n",
    "        next_psarl = self.select_col_from_obj(self.next_psarl, column).rename('Next_Long')\n",
    "        next_psars = self.select_col_from_obj(self.next_psars, column).rename('Next_Short')\n",
    "        \n",
    "        fig = close.vbt.plot(fig=fig, **close_kwargs, **layout_kwargs)\n",
    "        psarl.vbt.plot(fig=fig, **psarl_kwargs)\n",
    "        psars.vbt.plot(fig=fig, **psars_kwargs)\n",
    "        next_psarl.vbt.plot(fig=fig, **next_psarl_kwargs)\n",
    "        next_psars.vbt.plot(fig=fig, **next_psars_kwargs)\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = slice('2021-01-03', '2021-01-03 00:30:00')\n",
    "\n",
    "psar = PSAR.run(eth_min_data.high, eth_min_data.low, eth_min_data.close, af_0=0.02, af=0.02, max_af=0.2)\n",
    "psar.loc[date_range].plot(\n",
    "    psarl_kwargs=dict(trace_kwargs=dict(line_color='limegreen', mode='markers')),\n",
    "    psars_kwargs=dict(trace_kwargs=dict(line_color='red', mode='markers')),\n",
    "    next_psarl_kwargs=dict(trace_kwargs=dict(line_color='lightgreen', mode='markers', marker=dict(symbol='cross'))),\n",
    "    next_psars_kwargs=dict(trace_kwargs=dict(line_color='pink', mode='markers', marker=dict(symbol='cross'))),\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets upsample and downsample and align our psar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_period = '2h'\n",
    "resampled_eth = eth_min_data.resample(resample_period)\n",
    "psar = PSAR.run(resampled_eth.high, resampled_eth.low, resampled_eth.close, af_0=0.02, af=0.02, max_af=0.2)\n",
    "nb_psar_df = pd.concat([psar.next_psarl, psar.next_psars], axis=1)\n",
    "nb_psar_df.columns = ['psarl', 'psars']\n",
    "# Reindex to match the original ETH data\n",
    "nb_final_df = nb_psar_df.reindex(eth_min_data.get().index, method='ffill')\n",
    "# Join the PSAR values to the original ETH data\n",
    "nb_final_df = eth_min_data.get().join(nb_final_df)\n",
    "# final_df.loc['2019-01-03 07:00:00':'2019-01-03 09:00:00']\n",
    "\n",
    "# Print the final dataframe at a particular crossover point\n",
    "nb_final_df.iloc[230:250]\n",
    "nb_psar_df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the ETH data to 2 hour candles\n",
    "\n",
    "resample_period = '2h'\n",
    "resampled_eth = eth_min_data.resample(resample_period)\n",
    "psar = PSAR.run(resampled_eth.high, resampled_eth.low, resampled_eth.close, af_0=0.02, af=0.02, max_af=0.2)\n",
    "psar_df = pd.concat([psar.next_psarl, psar.next_psars], axis=1)\n",
    "psar_df.columns = ['psarl', 'psars']\n",
    "# Reindex to match the original ETH data\n",
    "final_df = psar_df.reindex(eth_min_data.get().index, method='ffill')\n",
    "# Join the PSAR values to the original ETH data\n",
    "final_df = eth_min_data.get().join(final_df)\n",
    "# Print the final dataframe at a particular crossover point\n",
    "\n",
    "# Create function to map the PSAR values to the lower resolution data\n",
    "@njit(nogil=True)\n",
    "def map_and_refine_psar_to_lower_res_nb(high, low, psarl, psars):\n",
    "    # Initialize the updated PSAR arrays with original values\n",
    "    updated_psarl = np.copy(psarl)\n",
    "    updated_psars = np.copy(psars)\n",
    "    \n",
    "    # Initialize variables for tracking the last known active PSAR values and breach indices\n",
    "    active_psarl, active_psars = None, None\n",
    "    # Iterate through the entire series\n",
    "    for i in range(len(high)):\n",
    "        \n",
    "        # Handle PSAR long (psarl)\n",
    "        if not np.isnan(psarl[i]):\n",
    "            active_psarl = psarl[i]\n",
    "            updated_psarl[i] = active_psarl\n",
    "        # Handle PSAR short (psars)\n",
    "        if not np.isnan(psars[i]):\n",
    "            active_psars = psars[i]\n",
    "            updated_psars[i] = active_psars\n",
    "            \n",
    "        # If psarl[i] is NaN, check if the current low has breached the last known active PSAR long value if not already breached set updated_psarl[i] to active_psarl\n",
    "        if np.isnan(psarl[i]) and (active_psarl is not None) and (low[i] > active_psarl):\n",
    "            updated_psarl[i] = active_psarl\n",
    "            # Handle the updated_psars[i] to make sure it is NaN if it has not been breached yet\n",
    "            updated_psars[i] = np.nan\n",
    "        if np.isnan(psars[i]) and (active_psars is not None) and (high[i] < active_psars):\n",
    "            updated_psars[i] = active_psars\n",
    "            # Handle the updated_psarl[i] to make sure it is NaN if it has not been breached yet\n",
    "            updated_psarl[i] = np.nan\n",
    "        # If psarl[i] is NaN, check if the current low has breached the last known active PSAR long value\n",
    "        if np.isnan(psarl[i]) and (active_psarl is not None) and (low[i] <= active_psarl):\n",
    "            # psarl_breach_index = i\n",
    "            updated_psarl[i] = active_psarl\n",
    "            active_psarl = None # Reset the active PSAR long value\n",
    "        # If psars[i] is NaN, check if the current high has breached the last known active PSAR short value\n",
    "        if np.isnan(psars[i]) and (active_psars is not None) and (high[i] >= active_psars):\n",
    "            # psars_breach_index = i\n",
    "            updated_psars[i] = active_psars\n",
    "            active_psars = None    \n",
    "\n",
    "    return updated_psarl, updated_psars\n",
    "\n",
    "# Create series to pass to the function\n",
    "high_prices = final_df['High'].values\n",
    "low_prices = final_df['Low'].values\n",
    "psarl = final_df['psarl'].values\n",
    "psars = final_df['psars'].values\n",
    "\n",
    "updated_psarl, updated_psars = map_and_refine_psar_to_lower_res_nb(high_prices, low_prices, psarl, psars)\n",
    "# from Ipython.display import display\n",
    "# Build a DataFrame with the updated PSAR values to compare to original psar series\n",
    "refined_psar_df = pd.DataFrame({'updated_psarl': updated_psarl, 'updated_psars': updated_psars}, index=eth_min_data.get().index)\n",
    "new_full_df = pd.concat([final_df, refined_psar_df], axis=1)\n",
    "# display(new_full_df.iloc[1190:1210])\n",
    "display(new_full_df.loc['2019-01-03 07:53:00+00:00':'2019-01-03 08:20:00+00:00'])\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# display(new_full_df.loc['2020-03-10 10:30:00':'2020-03-15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_psar_entries = (~new_full_df.updated_psarl.isnull()) #.vbt.signals.fshift()\n",
    "new_psar_exits = (~new_full_df.updated_psars.isnull()) #.vbt.signals.fshift()\n",
    "clean_entries, clean_exits = new_psar_entries.vbt.signals.clean(new_psar_exits)\n",
    "\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    # close=resampled_eth.close,\n",
    "    close=new_full_df.Close,\n",
    "    entries=clean_entries,\n",
    "    short_entries=clean_exits,\n",
    "    freq = '1min',\n",
    ")\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbt.phelp(PSAR.run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's create a pipeline and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorbt indicator factory\n",
    "PSAR = vbt.IF(\n",
    "    class_name = 'PSAR',\n",
    "    short_name = 'psar',\n",
    "    input_names = ['high', 'low', 'close'],\n",
    "    param_names = ['af_0', 'af', 'max_af'],\n",
    "    output_names = ['psarl', 'psars', 'psaraf', 'psarr', 'next_psarl', 'next_psars'],\n",
    ").with_apply_func(\n",
    "    psar_nb_with_next,\n",
    "    takes_1d=True,\n",
    "    af_0=0.02,\n",
    "    af=0.02,\n",
    "    max_af=0.2,\n",
    "    param_product=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_period = '1h'\n",
    "resampled_eth = eth_min_data.resample(resample_period)\n",
    "\n",
    "# Create a vectorbt indicator factory\n",
    "af0 = np.arange(0.01, 0.025, 0.001)\n",
    "af = np.arange(0.01, 0.02, 0.001)\n",
    "max_af = np.arange(0.05, 0.15, 0.02)\n",
    "psar = PSAR.run(resampled_eth.high, resampled_eth.low, resampled_eth.close, af_0=af0, af=af, max_af=max_af)\n",
    "\n",
    "# print(psar.psarl)\n",
    "\n",
    "entries = (~psar.next_psarl.isnull()) #.vbt.signals.fshift()\n",
    "exits = (~psar.next_psars.isnull()) #.vbt.signals.fshift()\n",
    "clean_entries, clean_exits = entries.vbt.signals.clean(exits)\n",
    "\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    close=resampled_eth.close,\n",
    "    open=resampled_eth.open,\n",
    "    high=resampled_eth.high,\n",
    "    low=resampled_eth.low,\n",
    "    entries=clean_entries,\n",
    "    short_entries=clean_exits,\n",
    "    freq = resample_period,\n",
    ")\n",
    "\n",
    "# pf.stats(agg_func=None).sort_values('Sharpe Ratio', ascending=False)\n",
    "pf.total_return.sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.total_return.vbt.volume().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf[pf.total_return.idxmax()].plot().show()\n",
    "print(pf[pf.total_return.idxmax()].stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_period = '30min'\n",
    "resampled_data = min_data.resample(resample_period)\n",
    "\n",
    "# Create a vectorbt indicator factory\n",
    "af0 = np.arange(0.005, 0.03, 0.002)\n",
    "af = np.arange(0.005, 0.03, 0.002)\n",
    "max_af = np.arange(0.1, 0.3, 0.01)\n",
    "psar = PSAR.run(\n",
    "    resampled_data.high, \n",
    "    resampled_data.low, \n",
    "    resampled_data.close, af_0=af0, af=af, max_af=max_af)\n",
    "\n",
    "# print(psar.psarl)\n",
    "\n",
    "entries = (~psar.next_psarl.isnull()) #.vbt.signals.fshift()\n",
    "exits = (~psar.next_psars.isnull()) #.vbt.signals.fshift()\n",
    "clean_entries, clean_exits = entries.vbt.signals.clean(exits)\n",
    "\n",
    "long_pf = vbt.Portfolio.from_signals(\n",
    "    close   =resampled_data.close,\n",
    "    open    =resampled_data.open,\n",
    "    high    =resampled_data.high,\n",
    "    low     =resampled_data.low,\n",
    "    entries=clean_entries,\n",
    "    exits=clean_exits,\n",
    "    freq = resample_period,\n",
    ")\n",
    "short_pf = vbt.Portfolio.from_signals(\n",
    "    close   =resampled_data.close,\n",
    "    open    =resampled_data.open,\n",
    "    high    =resampled_data.high,\n",
    "    low     =resampled_data.low,\n",
    "    short_entries=clean_exits,\n",
    "    short_exits=clean_entries,\n",
    "    freq = resample_period,\n",
    ")\n",
    "\n",
    "# pf.stats(agg_func=None).sort_values('Sharpe Ratio', ascending=False)\n",
    "display(long_pf.total_return.sort_values(ascending=False).head(10))\n",
    "print(\"Short Portfolio\")\n",
    "display(short_pf.total_return.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to filter for only BTC then we need to look at the 3rd level of the mult index call `pf.wrapper.columns` and you will see how the multindex is organized. \n",
    "`names=['psar_af_0', 'psar_af', 'psar_max_af', 'symbol']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(long_pf.total_return.xs('BTC', level=3).sort_values(ascending=False).head(5))\n",
    "display(long_pf.total_return.xs('ETH', level=3).sort_values(ascending=False).head(5))\n",
    "best_btc = long_pf.total_return.xs('BTC', level=3).idxmax() + ('BTC',) # Need to add back the BTC in the tuple for the index\n",
    "best_eth = long_pf.total_return.xs('ETH', level=3).idxmax() + ('ETH',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(long_pf[best_btc].stats())\n",
    "display(long_pf[best_eth].stats()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.wrapper.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf.sharpe_ratio.vbt.volume(\n",
    "    x_level='psar_af_0', \n",
    "    y_level='psar_af',\n",
    "    z_level='psar_max_af',\n",
    "    slider_level='symbol'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf[best_eth].plot().show()\n",
    "long_pf[best_eth].stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample_period = '30min'\n",
    "# resampled_data = min_data.resample(resample_period)\n",
    "# # Create a vectorbt indicator factory\n",
    "# af0 = np.arange(0.005, 0.03, 0.002)\n",
    "# af = np.arange(0.005, 0.03, 0.002)\n",
    "# max_af = np.arange(0.2, 0.3, 0.01)\n",
    "# psar = PSAR.run(\n",
    "#     resampled_data.high, \n",
    "#     resampled_data.low, \n",
    "#     resampled_data.close, af_0=af0, af=af, max_af=max_af)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# psar_df = pd.concat([psar.psarl, psar.psars], axis=1)\n",
    "\n",
    "# # Reindex to match the original ETH data\n",
    "# final_df = psar_df.reindex(eth_min_data.get().index, method='ffill')\n",
    "# # Join the PSAR values to the original ETH data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_period = '2h'\n",
    "resampled_eth = eth_min_data.resample(resample_period)\n",
    "psar = PSAR.run(resampled_eth.high, resampled_eth.low, resampled_eth.close, af_0=0.02, af=0.02, max_af=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_data = eth_min_data\n",
    "# psar.psarl.reindex(high_res_data.wrapper.index, method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_psar_pipeline(high_res_data, resample_period, af_0=0.02, af=0.02, max_af=0.2):\n",
    "    # Resample the PSAR data to the lower resolution\n",
    "    resampled_data = high_res_data.resample(resample_period)\n",
    "    # psar = PSAR.run(resampled_data.high, resampled_data.low, resampled_data.close, af_0=0.02, af=0.02, max_af=0.2)\n",
    "    \n",
    "    psar = PSAR.run(resampled_data.high, resampled_data.low, resampled_data.close, af_0=af_0, af=af, max_af=max_af)\n",
    "    \n",
    "    # Create function to map the PSAR values to the lower resolution data\n",
    "\n",
    "    # Resample back to the original resolution\n",
    "    high_res_psarl = psar.next_psarl.reindex(high_res_data.wrapper.index, method='ffill')\n",
    "    high_res_psars = psar.next_psars.reindex(high_res_data.wrapper.index, method='ffill')\n",
    "    high = high_res_data.high.values\n",
    "    low = high_res_data.low.values\n",
    "    psarl = high_res_psarl.values\n",
    "    psars = high_res_psars.values\n",
    "    updated_psarl, updated_psars = map_and_refine_psar_to_lower_res_nb(high, low, psarl, psars)\n",
    "    \n",
    "    # Build a DataFrame with the updated PSAR values to compare to original psar series\n",
    "    refined_psar_df = pd.DataFrame({'psarl': psarl, 'psars': psars, 'updated_psarl': updated_psarl, 'updated_psars': updated_psars}, index=high_res_data.wrapper.index)\n",
    "    new_full_df = pd.concat([high_res_data.get(), refined_psar_df], axis=1)\n",
    "    return new_full_df\n",
    "\n",
    "\n",
    "resample_period = '2h'\n",
    "new_full_df = resample_psar_pipeline(eth_min_data, resample_period, af_0=0.019, af=0.023, max_af=0.2)\n",
    "entries = (~new_full_df.updated_psarl.isnull()) #.vbt.signals.bshift()\n",
    "exits = (~new_full_df.updated_psars.isnull())\n",
    "clean_entries, clean_exits = entries.vbt.signals.clean(exits)\n",
    "resampled_eth = eth_min_data.resample(resample_period)\n",
    "resampled_atr = vbt.ATR.run(resampled_eth.high, resampled_eth.low, resampled_eth.close, window=15).tr\n",
    "\n",
    "atr = resampled_atr.reindex(new_full_df.index, method='ffill')\n",
    "date_range = slice('2019', '2023')\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    close       =new_full_df.loc[date_range].Close,\n",
    "    open        =new_full_df.loc[date_range].Open,\n",
    "    high        =new_full_df.loc[date_range].High,\n",
    "    low         =new_full_df.loc[date_range].Low,\n",
    "    entries     =clean_entries.loc[date_range],\n",
    "    short_entries       =clean_exits.loc[date_range],\n",
    "    freq = '1min',\n",
    "    init_cash=1000,\n",
    "    # tp_stop = atr.loc[date_range] * 5/new_full_df.loc[date_range].Close,\n",
    "    # sl_stop = atr.loc[date_range] * 3/new_full_df.loc[date_range].Close,\n",
    "    leverage=1,\n",
    "    \n",
    ")\n",
    "\n",
    "pf.resample('1d').plot(\n",
    "    # settings=dict(bm_returns=False)\n",
    "    ).show()\n",
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = new_full_df[['Close']].loc[date_range].vbt.plot()\n",
    "new_full_df[['updated_psarl', 'updated_psars']].loc[date_range].vbt.plot(fig=fig, trace_kwargs=dict(mode='markers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pf.trades.records_readable.sort_values('Return', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
